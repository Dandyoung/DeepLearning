{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, num_epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.num_errors = []\n",
    "    \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            num_errors = 0\n",
    "            for xi, yi in zip(X, y):\n",
    "                # feature vector normalization\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                # 예측값 계산\n",
    "                y_pred = self.predict(xi_norm)\n",
    "                # 가중치 업데이트\n",
    "                self.weights += self.learning_rate * (yi - y_pred) * xi_norm\n",
    "                # 분류 오류 개수 계산\n",
    "                num_errors += int(yi != y_pred)\n",
    "            self.num_errors.append(num_errors)\n",
    "            # 0에서 30까지의 Iteration에 대해서 그래프로 나타냄\n",
    "            if epoch+1 in range(1,31):\n",
    "                plt.plot(range(1,epoch+2), self.num_errors)\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('Number of Errors')\n",
    "                plt.title('Errors in Iterations 0 to 30')\n",
    "                plt.show()\n",
    "                \n",
    "            if num_errors == 0:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product > 0 else 0\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "for xi, yi in zip(X_test, y_test):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, num_epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_errors = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            errors = 0\n",
    "            for xi, yi in zip(X, y):\n",
    "                # feature vector normalization\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                # 예측값 계산\n",
    "                y_pred = self.predict(xi_norm)\n",
    "                # 가중치 업데이트\n",
    "                self.weights += self.learning_rate * (yi - y_pred) * xi_norm\n",
    "                # 분류 오류 개수 카운트\n",
    "                errors += int(yi != y_pred)\n",
    "            self.num_errors.append(errors)\n",
    "            if epoch+1 in range(1,31):\n",
    "                plt.plot(range(1,epoch+2), self.num_errors[:epoch+1], color='gray')\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product > 0 else 0\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "for xi, yi in zip(X_test, y_test):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(range(1,31), model.num_errors[:30], color='red')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Number of Errors')\n",
    "plt.title('Errors in Iterations 0 to 30')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, num_epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_errors = []  # 각 Iteration에서 분류 오류의 개수를 저장할 리스트\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            num_errors = 0  # 매 Iteration마다 분류 오류의 개수를 초기화\n",
    "            for xi, yi in zip(X, y):\n",
    "                # feature vector normalization\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                # 예측값 계산\n",
    "                y_pred = self.predict(xi_norm)\n",
    "                # 가중치 업데이트\n",
    "                self.weights += self.learning_rate * (yi - y_pred) * xi_norm\n",
    "                # 분류 오류 개수 계산\n",
    "                if yi != y_pred:\n",
    "                    num_errors += 1\n",
    "            # 매 Iteration마다 분류 오류 개수를 업데이트\n",
    "            self.num_errors.append(num_errors)\n",
    "            \n",
    "            if epoch+1 in range(1,31):\n",
    "                plt.plot(range(1,epoch+2), self.num_errors[:epoch+1], marker='o')\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('제대로 분류되지 않은 데이터 개수')\n",
    "                plt.title('')\n",
    "                plt.xticks(range(1, epoch+2))\n",
    "                plt.grid(True)\n",
    "            plt.show()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product > 0 else 0\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "for xi, yi in zip(X_test, y_test):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, num_epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_errors = []  # 각 Iteration에서 분류 오류의 개수를 저장할 리스트\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            num_errors = 0  # 매 Iteration마다 분류 오류의 개수를 초기화ㄴ\n",
    "            for xi, yi in zip(X, y):\n",
    "                # feature vector normalization\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                # 예측값 계산\n",
    "                y_pred = self.predict(xi_norm)\n",
    "                # 가중치 업데이트\n",
    "                self.weights += self.learning_rate * (yi - y_pred) * xi_norm\n",
    "                # 분류 오류 개수 계산\n",
    "                if yi != y_pred:\n",
    "                    num_errors += 1\n",
    "            # 매 Iteration마다 분류 오류 개수를 업데이트\n",
    "            self.num_errors.append(num_errors)\n",
    "            \n",
    "            if epoch+1 in range(1,31):\n",
    "                plt.plot(range(1,epoch+2), self.num_errors[:epoch+1], marker='o')\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('제대로 분류되지 않은 데이터 개수')\n",
    "                plt.title('')\n",
    "                plt.xticks(range(1, epoch+2))\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product > 0 else 0\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "for xi, yi in zip(X_test, y_test):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, num_epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_errors = []  # 각 Iteration에서 분류 오류의 개수를 저장할 리스트\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.random.random(X.shape[1])\n",
    "        \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            num_errors = 0  # 매 Iteration마다 분류 오류의 개수를 초기화\n",
    "            for xi, yi in zip(X, y):\n",
    "                # feature vector normalization\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                # 예측값 계산\n",
    "                y_pred = self.predict(xi_norm)\n",
    "                # 가중치 업데이트\n",
    "                self.weights += self.learning_rate * (yi - y_pred) * xi_norm\n",
    "                # 분류 오류 개수 계산\n",
    "                if yi != y_pred:\n",
    "                    num_errors += 1\n",
    "            # 매 Iteration마다 분류 오류 개수를 업데이트\n",
    "            self.num_errors.append(num_errors)\n",
    "            \n",
    "            if epoch+1 in range(1,31):\n",
    "                plt.plot(range(1,epoch+2), self.num_errors[:epoch+1], marker='o')\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('제대로 분류되지 않은 데이터 개수')\n",
    "                plt.title('')\n",
    "                plt.xticks(range(1, epoch+2))\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "for xi, yi in zip(X_test, y_test):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization이 된 feature vector를 사용한 퍼셉트론은 각 feature들의 스케일을 맞추고 분산을 조절하는 효과가 있습니다. 이로 인해 특정 feature가 가지는 값이 크다고 해서 가중치 업데이트에 더 많은 영향을 주는 것을 방지할 수 있어서 모델이 더욱 안정적으로 학습할 수 있습니다.\n",
    "\n",
    "하지만 여기서는 feature의 값이 크지 않은 데이터셋이므로 이점이 크게 나타나지 않았을 가능성이 있습니다. 또한 이 데이터셋에서는 클래스 간 경계가 선형이기 때문에 normalization이 큰 차이를 내지 못한 것일 수도 있습니다.\n",
    "\n",
    "따라서 normalization이 큰 효과를 내지 않는 경우가 있을 수 있으며, 이 경우에는 normalization을 하지 않아도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_epochs=1000):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_errors = []  # 각 Iteration에서 분류 오류의 개수를 저장할 리스트\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            num_errors = 0  # 매 Iteration마다 분류 오류의 개수를 초기화\n",
    "            for xi, yi in zip(X, y):\n",
    "                # feature vector normalization\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                # 예측값 계산\n",
    "                y_pred = self.predict(xi_norm)\n",
    "                # 가중치 업데이트\n",
    "                self.weights += (yi - y_pred) * xi_norm\n",
    "                # 분류 오류 개수 계산\n",
    "                if yi != self.predict(xi_norm):\n",
    "                    num_errors += 1\n",
    "            # 매 Iteration마다 분류 오류 개수를 업데이트\n",
    "            self.num_errors.append(num_errors)\n",
    "            \n",
    "            if epoch+1 in range(1,31):\n",
    "                plt.plot(range(1,epoch+2), self.num_errors[:epoch+1], marker='o')\n",
    "                plt.xlabel('Iteration')\n",
    "                plt.ylabel('제대로 분류되지 않은 데이터 개수')\n",
    "                plt.title('Iteration {} - Error Count'.format(epoch+1))\n",
    "                plt.xticks(range(1, epoch+2))\n",
    "                plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product >= 0 else 0\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "for xi, yi in zip(X_test, y_test):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "train_correct = 0\n",
    "for xi, yi in zip(X_train, y_train):\n",
    "    # feature vector normalization\n",
    "    xi_norm = xi / np.linalg.norm(xi)\n",
    "    # 예측값 계산\n",
    "    y_pred = model.predict(xi_norm)\n",
    "    if y_pred == yi:\n",
    "        train_correct += 1\n",
    "\n",
    "train_accuracy = train_correct / 2000\n",
    "print('Train Accuracy:', train_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_epochs=20):\n",
    "        self.num_epochs = num_epochs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weight vector 초기화\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # 학습\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # 분류 오류 개수 초기화\n",
    "            num_errors = 0\n",
    "            # M+에 대해 w 업데이트\n",
    "            for xi, yi in zip(X[y == 1], y[y == 1]):\n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                if np.dot(xi, self.weights) <= 0:\n",
    "                    self.weights += xi_norm / abs(xi)\n",
    "                    print(xi_norm / abs(xi))\n",
    "                    num_errors += 1\n",
    "            # M-에 대해 w 업데이트\n",
    "            for xi, yi in zip(X[y == 0], y[y == 0]): \n",
    "                xi_norm = xi / np.linalg.norm(xi)\n",
    "                if np.dot(xi, self.weights) > 0:\n",
    "                    self.weights -= xi_norm / abs(xi)\n",
    "                    num_errors += 1\n",
    "            # 모든 데이터가 제대로 분류되면 학습 종료\n",
    "            if num_errors == 0:\n",
    "                break\n",
    "        #print(f\"Number of errors: {num_errors}\")\n",
    "        #print(f\"Final weights: {self.weights}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 결정 경계 함수\n",
    "        dot_product = np.dot(X, self.weights)\n",
    "        return 1 if dot_product > 0 else 0\n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        y_pred = np.apply_along_axis(self.predict, 1, X)\n",
    "        return np.mean(y_true == y_pred)\n",
    "    \n",
    "# 데이터셋 로딩\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "# 특징벡터와 클래스 분리\n",
    "X_train, y_train = train_data[:, :3], train_data[:, 3]\n",
    "X_test, y_test = test_data[:, :3], test_data[:, 3]\n",
    "\n",
    "# 모델 학습\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "accuracy = perceptron.score(X_train, y_train)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "#accuracy = perceptron.score(X_test, y_test)\n",
    "#print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# # 모델 평가\n",
    "# correct = 0\n",
    "# for xi, yi in zip(X_test, y_test):\n",
    "#     xi_norm = xi / np.linalg.norm(xi)  # feature vector normalization\n",
    "#     y_pred = Perceptron(xi_norm)\n",
    "#     if y_pred == yi:\n",
    "#         correct += 1\n",
    "\n",
    "# accuracy = correct / len(y_test)\n",
    "# print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 평가\n",
    "# correct = 0\n",
    "# for xi, yi in zip(X_test, y_test):\n",
    "#     xi_norm = xi / abs(xi)  # feature vector normalization\n",
    "#     y_pred = model.predict(xi_norm)\n",
    "#     if y_pred == yi:\n",
    "#         correct += 1\n",
    "# accuracy = correct / len(y_test)\n",
    "# print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[658, 345, 263, 226, 211, 191, 166, 155, 146, 140, 110, 123, 131, 145, 121, 99, 113, 107, 101, 102, 80, 99, 101, 97, 105, 98, 94, 100, 86, 84]\n",
      "Accuracy :  0.9775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "class Perceptron():\n",
    "\n",
    "    def __init__(self, n_iter=1000):\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def perceptronLearning(self, x, w):\n",
    "        check_break = 0\n",
    "        self.w = w\n",
    "\n",
    "        for i in range(2000) :\n",
    "            X_normalized = x[i][:4] / np.linalg.norm(x[i][:4])\n",
    "            check = np.dot(self.w, x[i][:4])\n",
    "\n",
    "            if x[i, 4] == 1 :\n",
    "                if check <= 0 :\n",
    "                    self.w += X_normalized\n",
    "                    check_break +=1\n",
    "\n",
    "            elif x[i, 4] == 0 : \n",
    "                if check > 0 :\n",
    "                    self.w -= X_normalized\n",
    "                    check_break +=1\n",
    "\n",
    "        return w, check_break\n",
    "\n",
    "    def predict(self, x, w):\n",
    "        pred_class_list = []\n",
    "\n",
    "        for i in range(400):\n",
    "            check = np.dot(x[i, :4], w)\n",
    "        \n",
    "            if check > 0 :\n",
    "                pred_class = 1.0\n",
    "                pred_class_list.append(float(pred_class))\n",
    "                \n",
    "            else :\n",
    "                pred_class = 0.0\n",
    "                pred_class_list.append(float(pred_class))\n",
    "\n",
    "        return pred_class_list\n",
    "\n",
    "    def accuracy(self, x, y):\n",
    "        train_data = x\n",
    "        test_data = y\n",
    "        train_data = np.insert(train_data, 3, 1, axis=1)\n",
    "        check_break_list = []\n",
    "        w = np.random.random(4)\n",
    "\n",
    "        for i in range (1000):\n",
    "             \n",
    "             w, check_break = self.perceptronLearning(train_data, w)\n",
    "\n",
    "             if check_break == 0 :\n",
    "                 break\n",
    "             \n",
    "             else :\n",
    "                 if i < 30 : \n",
    "                    check_break_list.append(check_break)\n",
    "                 check_break = 0\n",
    "        #print(check_break_list)\n",
    "\n",
    "        test_data = np.insert(test_data, 3, 1, axis=1)\n",
    "\n",
    "        preds = self.predict(test_data, w)\n",
    "        label = test_data[:, 4].tolist()\n",
    "\n",
    "\n",
    "        accuracy_score = 0.0\n",
    "        for i in range (400):\n",
    "            if preds[i] == label[i]:\n",
    "                accuracy_score +=1.0\n",
    "\n",
    "        accuracy = accuracy_score / float(len(preds))\n",
    "        return accuracy\n",
    "\n",
    "train_data = np.loadtxt('synthetic_data_train.txt', delimiter=',')\n",
    "test_data = np.loadtxt('synthetic_data_test.txt', delimiter=',')\n",
    "\n",
    "\n",
    "test = Perceptron()\n",
    "\n",
    "accuracy = test.accuracy(train_data, test_data)\n",
    "print('Accuracy : ', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
